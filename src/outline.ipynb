{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.7.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "## Libraries import\n",
    "\n",
    "import carla, time, pygame, cv2, math, random, os, traceback\n",
    "# import paho.mqtt.client as mqtt\n",
    "import numpy as np\n",
    "import tkinter as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Carla set up\n",
    "\n",
    "try:\n",
    "    client = carla.Client('localhost', 2000)\n",
    "    client.set_timeout(10.0)\n",
    "    world = client.get_world()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to CARLA: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "if not all(os.path.exists(f) for f in [\"yolov4-tiny.weights\", \"yolov4-tiny.cfg\"]):\n",
    "    print(\"YOLO model files not found!\")\n",
    "    exit(1)\n",
    "\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()\n",
    "carla_settings = world.get_settings()\n",
    "\n",
    "capture = True\n",
    "stored_image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utliity functions\n",
    "\n",
    "def spawn_vehicle(world, vehicle_index=0, spawn_index=0):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter('vehicle.*')[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "def spawn_walker(world):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    \n",
    "    # Get a random pedestrian blueprint\n",
    "    walker_bp = random.choice(blueprint_library.filter('walker.pedestrian.*'))\n",
    "    \n",
    "    # Set a random speed\n",
    "    speed = random.uniform(0.8, 2.0)\n",
    "    walker_bp.set_attribute('speed', str(speed))\n",
    "    \n",
    "    # Get a random spawn point\n",
    "    spawn_points = world.get_map().get_spawn_points()\n",
    "    spawn_point = random.choice(spawn_points) if spawn_points else carla.Transform()\n",
    "    \n",
    "    # Spawn the pedestrian\n",
    "    walker = world.try_spawn_actor(walker_bp, spawn_point)\n",
    "    if not walker:\n",
    "        return None, None  # Return None if spawning failed\n",
    "    \n",
    "    # Spawn the AI controller\n",
    "    controller_bp = blueprint_library.find('controller.ai.walker')\n",
    "    controller = world.try_spawn_actor(controller_bp, carla.Transform(), walker)\n",
    "    \n",
    "    if controller:\n",
    "        # Start the pedestrian's movement\n",
    "        controller.start()\n",
    "        destination = world.get_random_location_from_navigation()\n",
    "        if destination:\n",
    "            controller.go_to_location(destination)\n",
    "        controller.set_max_speed(speed)  # Set the max speed\n",
    "    \n",
    "    return walker, controller\n",
    "\n",
    "def callback(image):\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    time.sleep(3)\n",
    "    image.save_to_disk('output/%.6d.png' % image.frame)\n",
    "\n",
    "def render(image, display):\n",
    "    if image is not None:\n",
    "        array = np.frombuffer(image.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "        array = np.reshape(array, (image.height, image.width, 4))\n",
    "        array = array[:,:,:3]\n",
    "        array = array[:,:,::-1]\n",
    "        raw_image = cv2.cvtColor(array, cv2.COLOR_BGR2RGB)\n",
    "        return raw_image\n",
    "    \n",
    "def image_processing(image, target_size):\n",
    "    ih, iw = target_size\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    scale = min(iw / w, ih / h)\n",
    "    nw, nh = int(scale * w), int(scale * h)\n",
    "\n",
    "    image_resized = cv2.resize(image, (nw, nh), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    image_padded = np.full((ih, iw, 3), 128.0)\n",
    "    dw, dh = (iw - nw) // 2, (ih - nh) // 2\n",
    "    image_padded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
    "\n",
    "    image_padded = image_padded / 255.0\n",
    "    return image_padded.astype(np.float32)\n",
    "\n",
    "def move_spectator_to(transform, spectator, distance=5.0, x=0, y=0, z=4, yaw=0, pitch=-30, roll=0):\n",
    "    back_location = transform.location - transform.get_forward_vector() * distance\n",
    "\n",
    "    back_location.x += x\n",
    "    back_location.y += y\n",
    "    back_location.z += z\n",
    "    transform.rotation.yaw += yaw\n",
    "    transform.rotation.pitch = pitch\n",
    "    transform.rotation.roll = roll\n",
    "\n",
    "    spectator_transform = carla.Transform(back_location, transform.rotation)\n",
    "\n",
    "    spectator.set_transform(spectator_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## warning system (using MQTT)\n",
    "\n",
    "def brake(vehicle):\n",
    "    \"\"\"Apply emergency braking to the vehicle.\"\"\"\n",
    "    control = carla.VehicleControl()\n",
    "    control.throttle = 0.0\n",
    "    control.brake = 1.0\n",
    "    vehicle.apply_control(control)\n",
    "\n",
    "# mqtt_client = mqtt.Client()\n",
    "# mqtt_client.connect(\"localhost\", 1883, 60)\n",
    "\n",
    "def send_warning(vehicle):\n",
    "    # mqtt_client.publish(\"warning\", \"Warning! Collision imminent!\")\n",
    "    brake(vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main utility functions\n",
    "\n",
    "VIEW_WIDTH = tk.Tk().winfo_screenwidth()//3\n",
    "VIEW_HEIGHT = tk.Tk().winfo_screenheight()//3\n",
    "VIEW_FOV = 90\n",
    "\n",
    "BB_COLOR = (248, 64, 24)\n",
    "\n",
    "def camera_blueprint():\n",
    "    \"\"\"\n",
    "    Returns camera blueprint.\n",
    "    \"\"\"\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(VIEW_WIDTH))\n",
    "    camera_bp.set_attribute('image_size_y', str(VIEW_HEIGHT))\n",
    "    camera_bp.set_attribute('fov', str(VIEW_FOV))\n",
    "\n",
    "    return camera_bp\n",
    "\n",
    "def setup_car():\n",
    "    \"\"\"\n",
    "    Spawns actor-vehicle to be controled.\n",
    "    \"\"\"\n",
    "    car_bp = world.get_blueprint_library().filter('vehicle.*')[0]\n",
    "    location = random.choice(world.get_map().get_spawn_points())\n",
    "    car = world.spawn_actor(car_bp, location)\n",
    "    return car\n",
    "\n",
    "def callback(image):\n",
    "    \"\"\"\n",
    "    Callback function to be called when new image is received.\n",
    "    \"\"\"\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    time.sleep(3)\n",
    "    image.save_to_disk('output/%.6d.png' % image.frame)\n",
    "\n",
    "def set_image(img):\n",
    "    global stored_image\n",
    "    global capture\n",
    "    if capture:\n",
    "        stored_image = img\n",
    "        capture = False\n",
    "\n",
    "stored_rgb_image = None\n",
    "stored_depth_image = None\n",
    "\n",
    "def set_rgb_image(image):\n",
    "    \"\"\"Stores the latest RGB image.\"\"\"\n",
    "    global stored_rgb_image\n",
    "    stored_rgb_image = image\n",
    "\n",
    "def set_depth_image(image):\n",
    "    \"\"\"Stores the latest Depth image.\"\"\"\n",
    "    global stored_depth_image\n",
    "    stored_depth_image = image\n",
    "\n",
    "\n",
    "def setup_camera(car):\n",
    "    \"\"\"\n",
    "    Spawns both an RGB and a Depth camera on the vehicle.\n",
    "    \"\"\"\n",
    "    camera_transform = carla.Transform(carla.Location(x=1.6, z=1.7), carla.Rotation(pitch=0))\n",
    "\n",
    "    # Get camera blueprints\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    \n",
    "    # RGB Camera\n",
    "    rgb_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "    rgb_bp.set_attribute('image_size_x', str(VIEW_WIDTH))\n",
    "    rgb_bp.set_attribute('image_size_y', str(VIEW_HEIGHT))\n",
    "    rgb_camera = world.spawn_actor(rgb_bp, camera_transform, attach_to=car)\n",
    "    rgb_camera.listen(lambda image: set_rgb_image(image))\n",
    "\n",
    "    # Depth Camera\n",
    "    depth_bp = blueprint_library.find('sensor.camera.depth')\n",
    "    depth_bp.set_attribute('image_size_x', str(VIEW_WIDTH))\n",
    "    depth_bp.set_attribute('image_size_y', str(VIEW_HEIGHT))\n",
    "    depth_camera = world.spawn_actor(depth_bp, camera_transform, attach_to=car)\n",
    "    depth_camera.listen(lambda image: set_depth_image(image))\n",
    "\n",
    "    # Camera calibration for image processing\n",
    "    calibration = np.identity(3)\n",
    "    calibration[0, 2] = VIEW_WIDTH / 2.0\n",
    "    calibration[1, 2] = VIEW_HEIGHT / 2.0\n",
    "    calibration[0, 0] = calibration[1, 1] = VIEW_WIDTH / (2.0 * np.tan(VIEW_FOV * np.pi / 360.0))\n",
    "    rgb_camera.calibration = calibration\n",
    "    depth_camera.calibration = calibration\n",
    "\n",
    "    return rgb_camera, depth_camera\n",
    "\n",
    "def get_depth_at_pixel(x, y):\n",
    "    \"\"\"\n",
    "    Retrieves the depth value (in meters) for a given pixel (x, y).\n",
    "    Assumes the stored_depth_image is in BGRA format.\n",
    "    \"\"\"\n",
    "    if stored_depth_image is None:\n",
    "        return None\n",
    "\n",
    "    if x < 0 or x >= stored_depth_image.width or y < 0 or y >= stored_depth_image.height:\n",
    "        raise ValueError(\"Pixel coordinates are out of bounds.\")\n",
    "\n",
    "    depth_array = np.frombuffer(stored_depth_image.raw_data, dtype=np.uint8)\n",
    "    depth_array = np.reshape(depth_array, (stored_depth_image.height, stored_depth_image.width, 4))\n",
    "\n",
    "    blue  = depth_array[y, x, 0]\n",
    "    green = depth_array[y, x, 1]\n",
    "    red   = depth_array[y, x, 2]\n",
    "\n",
    "    normalized_depth = (red + green * 256 + blue * 256**2) / (256**3 - 1)\n",
    "\n",
    "    depth_in_meters = normalized_depth * 1000.0\n",
    "\n",
    "    return depth_in_meters\n",
    "\n",
    "def control_car(car):\n",
    "    \"\"\"\n",
    "    Applies control to main car based on pygame pressed keys.\n",
    "    Will return True If ESCAPE is hit, otherwise False to end main loop.\n",
    "    \"\"\"\n",
    "    # move_spectator_to(car.get_transform(), spectator)\n",
    "    control = car.get_control()\n",
    "\n",
    "    control.brake = 0.0\n",
    "    control.steer = 0.0\n",
    "\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.KEYDOWN:\n",
    "            key = event.key\n",
    "            # print(key)\n",
    "            if key == pygame.K_ESCAPE:\n",
    "                return True # TODO:change\n",
    "            if key == pygame.K_w:\n",
    "                control.reverse = False\n",
    "                control.throttle = 0.6\n",
    "            if key == pygame.K_s:\n",
    "                control.reverse = True\n",
    "                control.throttle = 0.6\n",
    "            if key == pygame.K_a:\n",
    "                control.throttle = 0.4\n",
    "                control.steer = -0.45\n",
    "            if key == pygame.K_d:\n",
    "                control.throttle = 0.4\n",
    "                control.steer = 0.45\n",
    "\n",
    "        car.apply_control(control)\n",
    "\n",
    "def pedestrian_safety_monitoring(vehicle, results, reaction_time=1.5, deceleration=7.5):\n",
    "    \"\"\"\n",
    "    Monitors pedestrian safety using vehicle speed, braking distance, and depth camera data.\n",
    "    \n",
    "    - Stops the vehicle if a pedestrian is too close.\n",
    "    - Uses depth camera to get accurate pedestrian distances.\n",
    "    \"\"\"\n",
    "    # Get vehicle speed and compute minimum safe stopping distance\n",
    "    velocity = vehicle.get_velocity()\n",
    "    vehicle_speed = math.sqrt((velocity.x**2 + velocity.y**2 + velocity.z**2))\n",
    "\n",
    "    reaction_distance = vehicle_speed * reaction_time\n",
    "    braking_distance = (vehicle_speed ** 2) / (2 * deceleration)\n",
    "    # min_safe_distance = (reaction_distance + braking_distance) * 10\n",
    "    min_safe_distance = 4 # m\n",
    "    safe_distance_threshold = 1.5 # m\n",
    "\n",
    "    object_speed = 0  # Assume pedestrian speed is negligible\n",
    "    relative_speed = max(vehicle_speed - object_speed, 0.01)  # Avoid division by zero\n",
    "\n",
    "    for confidence, bbox, centroid in results:\n",
    "        depth = get_depth_at_pixel(int(centroid[0]), int(centroid[1]))\n",
    "        if depth is None or depth > 100:\n",
    "            continue\n",
    "\n",
    "        distance = depth\n",
    "\n",
    "        # print(f\"Distance {distance:.2f}m, Minimum Safe Distance: {min_safe_distance:.2f}m\")\n",
    "        control = vehicle.get_control()\n",
    "        if distance < min_safe_distance and vehicle_speed > 0.0:\n",
    "            control.throttle = 0.0\n",
    "            control.brake = 0.5\n",
    "            vehicle.apply_control(control)\n",
    "            print(\"Emergency braking\")\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            control_car(vehicle)\n",
    "\n",
    "def pedestrian_detection(image, model, layer_name, vehicle):\n",
    "    \"\"\"\n",
    "    Detects pedestrians in the image using YOLOv3 model.\n",
    "    \"\"\"\n",
    "    NMS_THRESHOLD = 0.3\n",
    "    MIN_CONFIDENCE = 0.2\n",
    "    (H, W) = image.shape[:2]\n",
    "    results = []\n",
    "    personidz = 0\n",
    "    # constructu blob and this will retirn the bounding boxes and confidence values\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),\n",
    "                                swapRB=True, crop=False)\n",
    "    model.setInput(blob)\n",
    "    layerOutputs = model.forward(layer_name)\n",
    "\n",
    "    boxes = []\n",
    "    centroids = []\n",
    "    confidences = []\n",
    "\n",
    "    # LayerOutputs is a list of lists containing outputs. Each list in layer output contains details about single prediction like its bounding box confidence\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            if classID == personidz and confidence > MIN_CONFIDENCE:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                centroids.append((centerX, centerY))\n",
    "                confidences.append(float(confidence))\n",
    "    # apply non-maxima suppression to suppress weak, overlapping\n",
    "    # bounding boxes\n",
    "    idzs = cv2.dnn.NMSBoxes(boxes, confidences, MIN_CONFIDENCE, NMS_THRESHOLD)\n",
    "    # ensure at least one detection exists\n",
    "    if len(idzs) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in idzs.flatten():\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            # update our results list to consist of the person\n",
    "            # prediction probability, bounding box coordinates,\n",
    "            # and the centroid\n",
    "            res = (confidences[i], (x, y, x + w, y + h), centroids[i])\n",
    "            results.append(res)\n",
    "    # return the list of results\n",
    "    pedestrian_safety_monitoring(vehicle, results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emergency braking\n",
      "Emergency braking\n",
      "\n",
      "Simulation interrupted by user\n",
      "Cleaning up...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Spawn vehicle\n",
    "        vehicle = setup_car()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Spawn camera\n",
    "        rgb_camera, depth_camera = setup_camera(vehicle)\n",
    "    \n",
    "        # Spawn test pedestrians (still)\n",
    "        walkers = []\n",
    "        controllers = []\n",
    "        for _ in range(50):\n",
    "            walker, controller = spawn_walker(world)\n",
    "            if walker and controller:\n",
    "                walkers.append(walker)\n",
    "                controllers.append(controller)\n",
    "\n",
    "        pygame.init()\n",
    "        pygame.display.set_mode((200,200))\n",
    "\n",
    "        display = pygame.display.set_mode((VIEW_WIDTH, VIEW_HEIGHT), pygame.HWSURFACE | pygame.DOUBLEBUF)\n",
    "\n",
    "        input_size = 416\n",
    "        \n",
    "        # labels_path = \"coco.names\"\n",
    "        # LABELS = open(labels_path).read().strip().split(\"\\n\")\n",
    "\n",
    "        weights_path = \"yolov4-tiny.weights\"\n",
    "        config_path = \"yolov4-tiny.cfg\"\n",
    "        model = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "        layer_name = model.getLayerNames()\n",
    "        layer_name = [layer_name[i - 1] for i in model.getUnconnectedOutLayers()]\n",
    "        writer = None\n",
    "\n",
    "        while True:\n",
    "            world.tick()\n",
    "            move_spectator_to(vehicle.get_transform(), spectator)\n",
    "            # Wait for both RGB and Depth images to be available\n",
    "            while stored_rgb_image is None or stored_depth_image is None:\n",
    "                world.tick()\n",
    "\n",
    "            # Convert images for YOLO processing\n",
    "            raw_image = render(stored_rgb_image, display)\n",
    "            raw_image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB)\n",
    "            # frame_size = raw_image.shape[:2]\n",
    "            image_data = image_processing(np.copy(raw_image), [input_size, input_size])\n",
    "            image_data = image_data[np.newaxis, ...]\n",
    "\n",
    "            results = pedestrian_detection(raw_image, model, layer_name, vehicle)\n",
    "\n",
    "            for res in results:\n",
    "                cv2.rectangle(raw_image, (res[1][0], res[1][1]), (res[1][2], res[1][3]), (0,255,0), 2)\n",
    "            cv2.imshow(\"Detection\", raw_image)\n",
    "\n",
    "            pygame.display.flip()\n",
    "            control_car(vehicle)\n",
    "            # time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        print('\\nSimulation interrupted by user')\n",
    "\n",
    "    finally:\n",
    "        print('Cleaning up...')\n",
    "        pygame.quit()\n",
    "        cv2.destroyAllWindows()\n",
    "        actors = world.get_actors()\n",
    "        # Cleanup\n",
    "        if 'rgb_camera' in locals():\n",
    "            rgb_camera.destroy()\n",
    "        if 'depth_camera' in locals():\n",
    "            depth_camera.destroy()\n",
    "        actors = world.get_actors()\n",
    "        for actor in actors:\n",
    "            if isinstance(actor, (carla.Vehicle, carla.Walker)):\n",
    "                actor.destroy()\n",
    "        print('Done.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        traceback.print_exc() \n",
    "        print(f'Exception occurred: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = world.get_actors()\n",
    "for actor in actors:\n",
    "    if isinstance(actor, carla.Vehicle) or isinstance(actor, carla.Walker):\n",
    "        actor.destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
